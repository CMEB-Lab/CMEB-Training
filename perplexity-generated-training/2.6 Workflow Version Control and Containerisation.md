<img src=“https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png” class=“logo” width=“120”/>

# Workflow, Version Control & Containerisation Training Manual (Module 2.6)

A 16-hour, competency-based program to master reproducible pipeline orchestration, collaborative version control, and containerized deployments essential for modern bioinformatics workflows and technical interviews.

## Learning Objectives

By module completion, learners will be able to:

1. Design and manage end-to-end pipelines using Snakemake or Nextflow.
2. Employ Git and GitHub for distributed version control, collaboration, and CI/CD.
3. Containerize workflows with Docker and Singularity for portability and reproducibility.
4. Integrate workflow engines, version control, and containers into a cohesive, automated pipeline.

## Week 1, Day 1 (4 hours): Version Control with Git & GitHub

### Topics

- Git fundamentals: repositories, commits, branches, merges, tags.
- Collaborative workflows: feature branches, pull requests, code review.
- Semantic commit messages and version tagging.
- GitHub Actions basics: CI workflows, linting, test-driven development.


### Exercises

1. **Initialize a project**:

```bash
git init bio-pipeline
cd bio-pipeline
echo “# Bioinformatics Pipeline” > README.md
git add README.md
git commit -m “chore: initial project skeleton”
git branch -M main
```

2. **Branching workflow**:
    - Create a `feature/snakemake-workflow` branch.
    - Simulate development of a `Snakefile`, commit iteratively with scoped messages (`feat: add Snakefile rule all`).
3. **Pull request simulation**:
    - Push branches to GitHub remote.
    - Open a PR, request review, address comments by amending commits or rebasing.
4. **CI integration**:
    - Add `.github/workflows/ci.yml` to run `snakemake —lint` and a basic `pytest` or `nextflow -check`.
    - Verify build passes on GitHub Actions.

## Week 1, Day 2 (4 hours): Workflow Orchestration with Snakemake

### Topics

- Snakemake DSL: rules, inputs/outputs, wildcards, resources.
- Configuration separation: `config.yaml`, profile management.
- Parallel execution and cluster integration (`—cores`, `—cluster`).
- Rule modules, wrappers, and conditional rules (checkpointing).


### Exercises

1. **Basic Snakefile**:

```python
rule all:
    input: expand(“results/{sample}.bam”, sample=[“A”,”B”])

rule map_reads:
    input:
        ref=“ref/genome.fa”,
        reads=“data/{sample}.fastq”
    output: “results/{sample}.bam”
    threads: 4
    shell:
        “bwa mem -t {threads} {input.ref} {input.reads} | samtools sort -o {output}”
```

2. **Config YAML**:

```yaml
samples:
  - A
  - B
resources:
  threads: 8
```

Load via `configfile: “config.yaml”` and replace hard-coded values.
3. **Scalable execution**:
    - Run locally: `snakemake —cores 4`.
    - Simulate cluster: `snakemake —cluster “qsub -pe smp {threads}” —jobs 10`.
4. **Checkpoint rule**: demonstrate a rule that downloads data only if missing, then resumes pipeline.

## Week 2, Day 3 (4 hours): Workflow Orchestration with Nextflow

### Topics

- Nextflow DSL 1 vs 2: processes, channels, operators.
- Parameterization and profiles (`nextflow.config`).
- Container support with `-with-docker` / `-with-singularity`.
- Reports: trace, timeline, DAG, and multiQC integration.


### Exercises

1. **Hello world pipeline**:

```groovy
params.reads = “data/*.fastq”
process map_reads {
  publishDir “mapped”, mode:”copy”
  input: path reads
  output: path(“${reads.baseName}.bam”)
  script:
  “””
  bwa mem ${reads} | samtools sort -o ${reads.baseName}.bam
  “””
}
workflow {
  Channel.fromPath(params.reads) | map_reads
}
```

2. **Profiles**: define `docker.enabled = true`, `executor = ‘local’` vs. `’slurm’` in `nextflow.config`.
3. **Execution & reports**:

```bash
nextflow run main.nf -profile docker —with-report report.html \
  —with-trace trace.txt —with-dag dag.png
```

4. **MultiQC integration**: collect logs and run `multiqc . -o multiqc_report`.

## Week 2, Day 4 (4 hours): Containerization with Docker & Singularity

### Topics

- Dockerfile anatomy: `FROM`, `RUN`, `COPY`, `ENTRYPOINT`.
- Best practices: multi-stage builds, minimal images, layer caching.
- Singularity conversion: `docker2singularity`, `Apptainer` basics.
- Registry usage: Docker Hub, GitHub Container Registry.


### Exercises

1. **Dockerfile for pipeline**:

```dockerfile
FROM continuumio/miniconda3
COPY environment.yml /app/
WORKDIR /app
RUN conda env create -f environment.yml
SHELL [“conda”, “run”, “-n”, “bioenv”, “/bin/bash”, “-c”]
COPY . /app
ENTRYPOINT [“bash”, “run_pipeline.sh”]
```

2. **Build & test**:

```bash
docker build -t bio-pipeline:latest .
docker run —rm bio-pipeline:latest
```

3. **Singularity image**:

```bash
singularity build bio-pipeline.sif docker-daemon://bio-pipeline:latest
singularity exec bio-pipeline.sif snakemake —cores 2
```

4. **Automated publishing**:
    - Add GitHub Action to build & push Docker image on `main` branch.

## Assessment Framework

| Competency Area | Beginner (0–60%) | Intermediate (61–80%) | Advanced (81–100%) |
| :— | :— | :— | :— |
| **Version Control (Git)** | Basic commits & branches | Feature workflows, PRs, CI integration | Complex rebases, submodules, advanced Actions workflows |
| **Snakemake Orchestration** | Simple Snakefile, local runs | Config profiles, cluster execution, wrappers | Checkpoints, dynamic DAGs, rule modules |
| **Nextflow Orchestration** | Core DSL processes | Profiles & containers, reporting | DSL2 modules, cloud executors, metrics dashboards |
| **Containerization** | Basic Dockerfile, local builds | Multi-stage builds, Singularity conversion | Image optimization, automated registry pipelines |
| **Pipeline Integration** | Separate scripts and containers | End-to-end Snakemake/Nextflow + containers | CI/CD pipeline, automated release tagging, reproducible deployments |

Upon completion, learners will be prepared to design, develop, and deploy robust, reproducible bioinformatics pipelines—demonstrating the workflow, version control, and containerization expertise expected in advanced research and technical interviews.

<div style="text-align: center">⁂</div>

[^1]: https://lachlandeer.github.io/snakemake-econ-r-tutorial/initial-steps-with-snakemake.html

[^2]: https://www.nextflow.io/docs/latest/your-first-script.html

[^3]: https://github.com/ehpc-lab/docker-conda-course

[^4]: https://github.com/roblehmann/snakemake-tutorial

[^5]: https://github.com/seqeralabs/nextflow-tutorial

[^6]: https://www.youtube.com/watch?v=AXKqF1I9ofk

[^7]: https://biojuse.com/2024/07/06/Snakemake pipeline 搭建的进阶教程/

[^8]: https://www.youtube.com/watch?v=sp45Bzri2sA

[^9]: https://www.numberanalytics.com/blog/docker-for-bioinformatics

[^10]: https://snakemake.readthedocs.io/en/stable/tutorial/basics.html

[^11]: https://bioinformaticsworkbook.org/dataAnalysis/nextflow/01_introductionToNextFlow.html

[^12]: https://lulab.gitbooks.io/teaching/content/appendix/appendix3.docker.html

[^13]: https://training.galaxyproject.org/training-material/topics/data-science/tutorials/snakemake/tutorial.html

[^14]: https://training.nextflow.io

[^15]: https://static-bcrf.biochem.wisc.edu/tutorials/docker/Docker_02.html

[^16]: https://snakemake.readthedocs.io/en/stable/tutorial/tutorial.html

[^17]: https://www.ebi.ac.uk/training/online/courses/nextflow

[^18]: https://book.ncrnalab.org/teaching/getting-started/docker

[^19]: https://www.youtube.com/watch?v=r9PWnEmz_tc

[^20]: https://nf-co.re/docs/tutorials/nextflow_training/nextflow

